![image](https://github.com/my-bro-pigeon/TP_Hardware/assets/94360349/3c82ddb8-0dd5-4b30-a26b-99495330bd4f)






<center><h1> **_Avant Propos_** </h1></center>

_L'objectif de ce projet est d'implÃ©menter un CNN classique : LeNet-5 en utilisant Cuda. Cela permet d'apprÃ©hender la parallÃ©lisation des calculs via l'utilisation de GPU NVidia_

Partie 1 - Prise en main de Cuda : Multiplication de matrices
-
## **Objectifs :** ğŸ¯

Allocation de la mÃ©moire // CrÃ©ation d'une matrice sur CPU // Affichage d'une matrice sur CPU // Addition de deux matrices sur CPU // Addition de deux matrices sur GPU-Multiplication de deux matrices NxN sur CPU // Multiplication de deux matrices NxN sur GPU // ComplÃ©xitÃ© et temps de calcul // ParamÃ©trage de votre programme

## **FIchier** ğŸ“

-> Matmult.cu : RÃ©alise la multiplication de deux matrices en comparant le temps de calcul du CPU et du GPU 

-> tester_limites.cu : Teste la limite du GPU en faisant des calculs de multiplication de matrices de plus en plus grand jusqu'Ã  10k x 10k 


Partie 2 - PremiÃ¨res couches du rÃ©seau de neurone LeNet-5 : Convolution 2D, subsampling et activation
-
## **Objectifs :** ğŸ¯

ImplÃ©mentation des premiÃ¨res couches de l'architecture du rÃ©seau LeNet-5 :

Layer 1- Couche d'entrÃ©e de taille 32x32 correspondant Ã  la taille des images de la base de donnÃ©e MNIST

Layer 2- Convolution avec 6 noyaux de convolution de taille 5x5. La taille rÃ©sultantes est donc de 6x28x28.

Layer 3- Sous-Ã©chantillonnage d'un facteur 2. La taille rÃ©sultantes des donnÃ©es est donc de 6x14x14.

**Fichier** ğŸ“

-> Partie2.cu : 

ImplÃ©mentation de la couche de convolution ainsi que la sous-echantillonnage et l'activation

On effectue un test simple : On prend une matrice d'entrÃ©e initialisÃ©e avec que des 1, un premier kernel avec un 2 au centre, un deuxiÃ¨me kernel avec un 1              au centre et les autre kernels Ã  0

On obtient bien en sortie un premier layer remplie de 0,96 (=tanh(2)) et un deuxiÃ¨me layer de 0,76 (=tanh(1))

Partie 3 - ModÃ¨le complet
-
## **Objectifs :** ğŸ¯

ImplÃ©mentation de toutes les couches du model // Importation du dataset MNIST // Exportation des poids du model

**Fichier** ğŸ“












